# Translator_transformer

## ç®€ä»‹
ä¸€ä¸ªä½¿ç”¨`Pytorch` æ„å»ºçš„ `Transformer æ¶æ„` è‹±è¯‘ä¸­ç¿»è¯‘ç¨‹åº <br>

## é¡¹ç›®ç»“æ„ 
`setting.py`:æ¨¡å‹ç›¸å…³å‚æ•°ï¼Œæ–‡ä»¶ç›®å½•çš„é…ç½®æ–‡ä»¶ã€‚  
`utils.py`:ä¸€äº›å·¥å…·å‡½æ•°ã€‚  
`data_pre.py`:æ•°æ®çš„é¢„å¤„ç†ï¼Œå¾—åˆ°è¾“å‡ºæ¨¡å‹çš„batchæ•°æ®å’Œç›¸å…³çš„maskçŸ©é˜µ  
`model.py`:æ¨¡å‹æ–‡ä»¶ã€‚  
`train.py`:è¿›è¡Œæ¨¡å‹çš„è®­ç»ƒã€‚å’Œæœ€å¥½æ¨¡å‹çš„ä¿å­˜ã€‚  
`test.py`:å¯¹æµ‹è¯•é›†å¥å­çš„æµ‹è¯•è¾“å‡ºã€‚  
`bleu_score.py`:å¯¹æœºå™¨ç¿»è¯‘è¯„åˆ†ã€‚  
`infer.py`:å®ç°å•ä¸ªå¥å­è¿›è¡Œç¿»è¯‘ã€‚  
`app.py`:é€šè¿‡ä½¿ç”¨infer.pyå°è£…çš„å•ä¸ªå¥å­ç¿»è¯‘çš„æ–¹æ³•ï¼Œå®ç°flask api  


## å¦‚ä½•ä½¿ç”¨
0. **é¡¹ç›®ç¬”è®°**

å¦‚æœæœ‰ä»»ä½•ç–‘é—®ğŸ¤”ï¸å¯ä»¥å‚è€ƒé¡¹ç›®ç¬”è®° ğŸ¤–ï¸[é¡¹ç›®ç¬”è®°ä¼ é€é—¨](https://github.com/chenjunyi1999/ML-Tutorial/tree/main/EN2CN%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0)
 
1. **ä¸‹è½½nltkä¾èµ–**

å¦‚æœä¹‹å‰å·²ç»ä¸‹è½½è¿‡ï¼Œè¿™ä¸€æ­¥å¯ä»¥è·³è¿‡
```python
import nltk
nltk.download('punkt')
```
2. **æ•°æ®å¤„ç†/æ¨¡å‹è®­ç»ƒ**
```
python train.py
```
 è®­ç»ƒå¥½çš„æ¨¡å‹ä¼šå­˜åœ¨ ./save æ–‡ä»¶å¤¹ä¸‹
3. **æ¨¡å‹äº¤äº’**

```
!python infer.py --sentence="I love you" 
```
4. **Flask API**

å¯åŠ¨flaskæœåŠ¡
```
python app.py
```
flask æ¥å£  `/translation` post æ–¹æ³•
```json
{
  "sentence": "è‹±æ–‡å¥å­"
}
// return
{
  "result": "ç¿»è¯‘ç»“æœ",
  "msg": 'success',
  "code": 200
}
```

## æ¨¡å‹è®­ç»ƒæ•°æ®
ä½¿ç”¨**14533**æ¡ç¿»è¯‘æ•°æ®è¿›è¡Œè®­ç»ƒã€‚  
æ•°æ®æ–‡ä»¶æ ¼å¼ï¼šen`\t`cn

    Anyone can do that.	ä»»ä½•äººéƒ½å¯ä»¥åšåˆ°ã€‚
    How about another piece of cake?	è¦ä¸è¦å†ä¾†ä¸€å¡Šè›‹ç³•ï¼Ÿ
    She married him.	å¥¹å«ç»™äº†ä»–ã€‚
    I don't like learning irregular verbs.	æˆ‘ä¸å–œæ¬¢å­¦ä¹ ä¸è§„åˆ™åŠ¨è¯ã€‚
  

## ç»“æœè¯„ä¼°
ä½¿ç”¨BLEUç®—æ³•è¿›è¡Œç¿»è¯‘æ•ˆæœè¯„ä¼°
BLEUç®—æ³•è¯„ä»·ç»“æœï¼š  
    
    å¯¹399æ¡ç¿»è¯‘å¥å­æ•ˆæœè¿›è¡Œè¯„ä¼°
    éªŒè¯é›†:0.1075088492716548ï¼Œn-gramæƒé‡ï¼š(1,0,0,0)
          0.03417978514554449,n-gramæƒé‡ï¼š(1,0.2,0,0)

## å‚è€ƒæ–‡çŒ®
1. [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)

2. [HarvardNLP "The Annotated Transformer"](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

3. [Transformer ä»£ç å®Œå…¨è§£è¯»](https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/120540057)

4. [Attentionä¸“åœº](https://blog.csdn.net/u012759262/article/details/103999959)

5. [taoztw/Transformer](https://github.com/taoztw/Transformer)
